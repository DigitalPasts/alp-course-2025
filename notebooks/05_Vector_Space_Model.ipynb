{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1cBcSJ8P-tBced7U_6_gbgWrxj1aLKjc7","timestamp":1715459002592}],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Intro\n","\n","In this notebook, we explore a collection of ancient Akkadian and ancient Egyptian texts using the vector space model approach described by [Karsdorp et al. in the chapter \"Exploring Texts using the Vector Space Model\"](https://www.humanitiesdataanalysis.org/vector-space-model/notebook.html). By representing the texts as numeric vectors capturing word frequencies, we can quantify the lexical similarities and differences between corpora in each of these two ancient languages. The vector space model allows us to reason about texts spatially and apply geometric concepts like distance metrics to assess how \"close\" texts are to each other based on shared vocabulary.\n","\n","We preprocess the texts by tokenizing them into words, constructing a document-term matrix recording word frequencies per text, and analyzing the matrix using tools from the Python scientific computing stack, including NumPy, SciPy and Scikit-learn. Through techniques like tSNE (t-Distributed Stochastic Neighbor Embedding) and aggregation by text metadata like script type, language or genre, we explore patterns in the Akkadian and Egyptian corpora and showcase how the vector space model can yield quantitative insights into ancient textual data. The notebook serves as an example application of the concepts and methods covered in depth by Karsdorp et al. in their chapter.\n","\n","This notebook has been prepared by **Avital Romach** and is based on her research. It should be cited accordingly (see citation information at the bottom)."],"metadata":{"id":"MWdwHvE2KbXH"}},{"cell_type":"markdown","source":["# Preprocessing the corpus"],"metadata":{"id":"3TBdIa1XSQos"}},{"cell_type":"markdown","source":["## Imports"],"metadata":{"id":"Lw5XXlgeG-kQ"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"nyHMlwmPGXC4","executionInfo":{"status":"ok","timestamp":1737385519760,"user_tz":-120,"elapsed":11229,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}}},"outputs":[],"source":["import os\n","import re\n","import numpy as np\n","import pandas as pd\n","import requests\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from scipy.spatial.distance import pdist, squareform\n","from sklearn.decomposition import PCA\n","from sklearn.manifold import TSNE\n","import plotly.express as px"]},{"cell_type":"markdown","source":["## Functions"],"metadata":{"id":"wO5SvgoORcfJ"}},{"cell_type":"markdown","source":["### To upload corpus and metadata from GitHub"],"metadata":{"id":"d9CCW78rHKOl"}},{"cell_type":"markdown","source":["#### Functions and import for the **Akkadian** corpus\n","\n","The Akkadian corpus consists of a part of the _[Royal Inscriptions of the Neo-Assyrian Period (RINAP)](https://colab.research.google.com/drive/14hTZCg-9XyiireusajDQqc9k2GAbc82e#scrollTo=qUcbzacX0kJy&line=3&uniqifier=1)_, licensed CC-BY-SA, and was taken from Open Richely Annotated Cuneiform Corpus (ORACC)."],"metadata":{"id":"qUcbzacX0kJy"}},{"cell_type":"code","source":["def create_corpus_from_github_api(url):\n","  # URL on the Github where the csv files are stored\n","  github_url = url\n","  response = requests.get(github_url)\n","\n","  corpus = []\n","  # Check if the request was successful\n","  if response.status_code == 200:\n","    files = response.json()\n","    for file in files:\n","      if file[\"download_url\"][-3:] == \"csv\":\n","        corpus.append(pd.read_csv(file[\"download_url\"], encoding=\"utf-8\", index_col=\"Unnamed: 0\").fillna(\"\"))\n","        # For Egyptian adapt like this:\n","        #corpus.append(pd.read_csv(file[\"download_url\"], encoding=\"utf-8\").fillna(\"\"))\n","  else:\n","    print('Failed to retrieve files:', response.status_code)\n","\n","  return corpus\n","\n","def get_metadata_from_raw_github(url):\n","  metadata = pd.read_csv(url, encoding=\"utf-8\", index_col=\"Unnamed: 0\").fillna(\"\")\n","  return metadata"],"metadata":{"id":"SBd1MSw6zT97","executionInfo":{"status":"ok","timestamp":1737385633433,"user_tz":-120,"elapsed":238,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Prepare Akkadian corpus (list of dataframes)\n","\n","corpus = create_corpus_from_github_api('https://api.github.com/repos/DigitalPasts/ALP-course/contents/course_notebooks/data/rinap01')\n","corpus.extend(create_corpus_from_github_api('https://api.github.com/repos/DigitalPasts/ALP-course/contents/course_notebooks/data/rinap05'))\n"],"metadata":{"id":"dojXSSkIxvgr","executionInfo":{"status":"ok","timestamp":1737385790185,"user_tz":-120,"elapsed":122495,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Prepare Akkadian metadata\n","metadata = get_metadata_from_raw_github(\"https://raw.githubusercontent.com/DigitalPasts/ALP-course/master/course_notebooks/data/rinap1_5_metadata.csv\")\n"],"metadata":{"id":"GixgIAtLyebb","executionInfo":{"status":"ok","timestamp":1737385803244,"user_tz":-120,"elapsed":723,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["#### Functions and import for the **Egyptian** corpus\n","\n","The Egyptian corpus is an extract of the database of the _[Thesaurus Linguae Aegyptiae (TLA)](https://thesaurus-linguae-aegyptiae.de)_, containing literary (and if you like: medical) texts. This export from the database is not published under a free license. Therefore, we access it from a private GitHub repository using an access token."],"metadata":{"id":"Cb_DROcmxxBl"}},{"cell_type":"code","source":["def create_corpus_from_private_github_api(url, token):\n","# URL on the Github where the csv files are stored\n","    headers = {\n","        \"Authorization\": f\"token {token}\"\n","    }\n","    github_url = url\n","    response = requests.get(github_url, headers=headers)\n","\n","    dtype_dict = {\"lemma_id\": \"str\"}\n","\n","    corpus = []\n","    # Check if the request was successful\n","    if response.status_code == 200:\n","        files = response.json()\n","        for file in files:\n","            if file[\"download_url\"][-3:] == \"csv\" or \".csv?token=\" in file[\"download_url\"]:\n","                corpus.append(pd.read_csv(file[\"download_url\"], encoding=\"utf-8\", sep = ',', dtype=dtype_dict).fillna(\"\"))\n","    else:\n","        print('Failed to retrieve files:', response.status_code)\n","\n","    return corpus\n","\n","from io import StringIO\n","\n","def get_metadata_from_raw_private_github(url, token):\n","    headers = {\n","        \"Authorization\": f\"token {token}\"\n","    }\n","    github_url = url\n","    response = requests.get(github_url, headers=headers)\n","\n","    # Check if the request was successful\n","    if response.status_code == 200:\n","        csv_data = StringIO(response.text)\n","        metadata = pd.read_csv(csv_data, encoding=\"utf-8\", sep = ',', index_col=\"text_id\").fillna(\"\")\n","        return metadata\n","    else:\n","        raise Exception(f\"Failed to retrieve metadata: {response.status_code}\")"],"metadata":{"id":"A7PyzjwSrz8r","executionInfo":{"status":"ok","timestamp":1737385519760,"user_tz":-120,"elapsed":2,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# only if corpus is not yet loaded\n","# Prepare Egyptian corpus (list sof dataframes)\n","\n","if False:\n","\n","  #tla_access_token = \"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\"\n","  tla_access_token = \"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\"\n","\n","  ## TLA Literature\n","  corpus = create_corpus_from_private_github_api('https://api.github.com/repos/thesaurus-linguae-aegyptiae/test-rawdata/contents/alp-course-2024/TLA_literature/erzaehlungen', tla_access_token)\n","\n","  corpus.extend(create_corpus_from_private_github_api('https://api.github.com/repos/thesaurus-linguae-aegyptiae/test-rawdata/contents/alp-course-2024/TLA_literature/reden', tla_access_token))\n","\n","  corpus.extend(create_corpus_from_private_github_api('https://api.github.com/repos/thesaurus-linguae-aegyptiae/test-rawdata/contents/alp-course-2024/TLA_literature/lehren', tla_access_token))\n","\n","  ## TLA Medical\n","  #corpus = create_corpus_from_private_github_api('https://api.github.com/repos/thesaurus-linguae-aegyptiae/test-rawdata/contents/alp-course-2024/TLA_medical/TLA_pEbers', tla_access_token)\n","\n","  #corpus.extend(create_corpus_from_private_github_api('https://api.github.com/repos/thesaurus-linguae-aegyptiae/test-rawdata/contents/alp-course-2024/TLA_medical/TLA_pEdwinSmith', tla_access_token))\n"],"metadata":{"id":"xnqvAC0Lr_nr","executionInfo":{"status":"ok","timestamp":1737385520262,"user_tz":-120,"elapsed":504,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d29f230d-0cd6-458b-cb15-4c0d29b87aee"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Failed to retrieve files: 401\n","Failed to retrieve files: 401\n","Failed to retrieve files: 401\n"]}]},{"cell_type":"code","source":["# Egyptian metadata\n","# metadata = get_metadata_from_raw_private_github(\"https://raw.githubusercontent.com/thesaurus-linguae-aegyptiae/test-rawdata/master/alp-course-2024/TLA_literature/TLA_metadata.csv\", tla_access_token)\n"],"metadata":{"id":"-4bDluLUy2hv","executionInfo":{"status":"error","timestamp":1737385521414,"user_tz":-120,"elapsed":1153,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}},"colab":{"base_uri":"https://localhost:8080/","height":266},"outputId":"f9fa699d-50dd-42f5-f684-846242026cb5"},"execution_count":7,"outputs":[{"output_type":"error","ename":"Exception","evalue":"Failed to retrieve metadata: 404","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-3058004b5d4e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Egyptian metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_metadata_from_raw_private_github\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://raw.githubusercontent.com/thesaurus-linguae-aegyptiae/test-rawdata/master/alp-course-2024/TLA_literature/TLA_metadata.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtla_access_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-5-af2596670e89>\u001b[0m in \u001b[0;36mget_metadata_from_raw_private_github\u001b[0;34m(url, token)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Failed to retrieve metadata: {response.status_code}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mException\u001b[0m: Failed to retrieve metadata: 404"]}]},{"cell_type":"code","source":["corpus[0].head()"],"metadata":{"id":"OYUZPigulF_b","colab":{"base_uri":"https://localhost:8080/","height":330},"executionInfo":{"status":"ok","timestamp":1737385860045,"user_tz":-120,"elapsed":524,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}},"outputId":"ba2bee97-bf42-4bae-fb06-e3f042033eb7"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["              ref                          inst         frag    norm      cf  \\\n","9515  Q003414.2.1  perʾu[bud//offspring]N$perʾi        NUNUZ   perʾi   perʾu   \n","9516  Q003414.2.2               Baltil[Aššur]QN  bal-til{ki}  Baltil  Baltil   \n","9517  Q003414.2.3       šūquru[very valuable]AJ   šu-⸢qu-ru⸣  šūquru  šūquru   \n","9518  Q003414.2.4             narām[loved one]N       na-ram   narām  narāmu   \n","9519  Q003414.2.5                             u    {d}[(...)                   \n","\n","              sense pos          unicode unicode_word      reading  \\\n","9515      offspring   N            ['𒉭']            𒉭        NUNUZ   \n","9516          Aššur  QN  ['𒁄', '𒌀', '𒆠']          𒁄𒌀𒆠  bal-til{KI}   \n","9517  very valuable  AJ  ['𒋗', '𒄣', '𒊒']          𒋗𒄣𒊒   šu-⸢qu-ru⸣   \n","9518      loved one   N       ['𒈾', '𒉘']           𒈾𒉘       na-ram   \n","9519                  u       ['𒀭', 'x']           𒀭x       {d}[x]   \n","\n","                                     break  break_perc mask lang     text  \\\n","9515                          ['complete']        0.00            Q003414   \n","9516  ['complete', 'complete', 'complete']        0.00            Q003414   \n","9517    ['complete', 'damaged', 'damaged']        0.33            Q003414   \n","9518              ['complete', 'complete']        0.00            Q003414   \n","9519               ['complete', 'missing']        0.50            Q003414   \n","\n","      line  word  \n","9515     2     1  \n","9516     2     2  \n","9517     2     3  \n","9518     2     4  \n","9519     2     5  "],"text/html":["\n","  <div id=\"df-be683b59-193d-42dd-92c6-93f4cc78eda9\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ref</th>\n","      <th>inst</th>\n","      <th>frag</th>\n","      <th>norm</th>\n","      <th>cf</th>\n","      <th>sense</th>\n","      <th>pos</th>\n","      <th>unicode</th>\n","      <th>unicode_word</th>\n","      <th>reading</th>\n","      <th>break</th>\n","      <th>break_perc</th>\n","      <th>mask</th>\n","      <th>lang</th>\n","      <th>text</th>\n","      <th>line</th>\n","      <th>word</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>9515</th>\n","      <td>Q003414.2.1</td>\n","      <td>perʾu[bud//offspring]N$perʾi</td>\n","      <td>NUNUZ</td>\n","      <td>perʾi</td>\n","      <td>perʾu</td>\n","      <td>offspring</td>\n","      <td>N</td>\n","      <td>['𒉭']</td>\n","      <td>𒉭</td>\n","      <td>NUNUZ</td>\n","      <td>['complete']</td>\n","      <td>0.00</td>\n","      <td></td>\n","      <td></td>\n","      <td>Q003414</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9516</th>\n","      <td>Q003414.2.2</td>\n","      <td>Baltil[Aššur]QN</td>\n","      <td>bal-til{ki}</td>\n","      <td>Baltil</td>\n","      <td>Baltil</td>\n","      <td>Aššur</td>\n","      <td>QN</td>\n","      <td>['𒁄', '𒌀', '𒆠']</td>\n","      <td>𒁄𒌀𒆠</td>\n","      <td>bal-til{KI}</td>\n","      <td>['complete', 'complete', 'complete']</td>\n","      <td>0.00</td>\n","      <td></td>\n","      <td></td>\n","      <td>Q003414</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>9517</th>\n","      <td>Q003414.2.3</td>\n","      <td>šūquru[very valuable]AJ</td>\n","      <td>šu-⸢qu-ru⸣</td>\n","      <td>šūquru</td>\n","      <td>šūquru</td>\n","      <td>very valuable</td>\n","      <td>AJ</td>\n","      <td>['𒋗', '𒄣', '𒊒']</td>\n","      <td>𒋗𒄣𒊒</td>\n","      <td>šu-⸢qu-ru⸣</td>\n","      <td>['complete', 'damaged', 'damaged']</td>\n","      <td>0.33</td>\n","      <td></td>\n","      <td></td>\n","      <td>Q003414</td>\n","      <td>2</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>9518</th>\n","      <td>Q003414.2.4</td>\n","      <td>narām[loved one]N</td>\n","      <td>na-ram</td>\n","      <td>narām</td>\n","      <td>narāmu</td>\n","      <td>loved one</td>\n","      <td>N</td>\n","      <td>['𒈾', '𒉘']</td>\n","      <td>𒈾𒉘</td>\n","      <td>na-ram</td>\n","      <td>['complete', 'complete']</td>\n","      <td>0.00</td>\n","      <td></td>\n","      <td></td>\n","      <td>Q003414</td>\n","      <td>2</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>9519</th>\n","      <td>Q003414.2.5</td>\n","      <td>u</td>\n","      <td>{d}[(...)</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td>u</td>\n","      <td>['𒀭', 'x']</td>\n","      <td>𒀭x</td>\n","      <td>{d}[x]</td>\n","      <td>['complete', 'missing']</td>\n","      <td>0.50</td>\n","      <td></td>\n","      <td></td>\n","      <td>Q003414</td>\n","      <td>2</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be683b59-193d-42dd-92c6-93f4cc78eda9')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-be683b59-193d-42dd-92c6-93f4cc78eda9 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-be683b59-193d-42dd-92c6-93f4cc78eda9');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-6c982fde-71a0-4f0b-912d-fdda6caa2328\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6c982fde-71a0-4f0b-912d-fdda6caa2328')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-6c982fde-71a0-4f0b-912d-fdda6caa2328 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","repr_error":"0"}},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# Prepare text_ids (list of unique ids), and metadata\n","\n","text_ids = []\n","for text in corpus:\n","  text_ids.append(text[\"text\"].iloc[0])\n","\n","\n","for id in text_ids:\n","  if id not in metadata.index:\n","    print(f\"Text {id} missing from metadata\")\n","\n","metadata = metadata[metadata.index.isin(text_ids)]\n","\n","metadata"],"metadata":{"id":"FgnIN_DKGRMX","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1737385864555,"user_tz":-120,"elapsed":241,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}},"outputId":"3986a404-4028-4574-a6bf-a5628050262a"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["              langs       project  cdli_id  \\\n","Q003414  0x08000000  rinap/rinap1  P463047   \n","Q003415  0x08000000  rinap/rinap1  P463047   \n","Q003416  0x08000000  rinap/rinap1  P463048   \n","Q003417  0x08000000  rinap/rinap1  P463048   \n","Q003418  0x08000000  rinap/rinap1  P463049   \n","...             ...           ...      ...   \n","Q009295  0x08000000  rinap/rinap5            \n","Q009296  0x08000000  rinap/rinap5            \n","Q009297  0x08000000  rinap/rinap5            \n","Q009298  0x08000000  rinap/rinap5            \n","Q009503  0x08000000  rinap/rinap5            \n","\n","                                                collection  \\\n","Q003414  Archäologisches Institut der Universität Züric...   \n","Q003415                                                      \n","Q003416                                                      \n","Q003417                                                      \n","Q003418                         British Museum, London, UK   \n","...                                                    ...   \n","Q009295                         British Museum, London, UK   \n","Q009296                         British Museum, London, UK   \n","Q009297                         British Museum, London, UK   \n","Q009298                                                      \n","Q009503                         British Museum, London, UK   \n","\n","                                                   credits date_of_origin  \\\n","Q003414  Created by Hayim Tadmor, Shigeo Yamada, Jamie ...        744-727   \n","Q003415  Created by Hayim Tadmor, Shigeo Yamada, Jamie ...        744-727   \n","Q003416  Created by Hayim Tadmor, Shigeo Yamada, Jamie ...        744-727   \n","Q003417  Created by Hayim Tadmor, Shigeo Yamada, Jamie ...        744-727   \n","Q003418  Created by Hayim Tadmor, Shigeo Yamada, Jamie ...        744-727   \n","...                                                    ...            ...   \n","Q009295  Created by Jamie Novotny and Joshua Jeffers, 2...    668-ca. 631   \n","Q009296  Created by Jamie Novotny and Joshua Jeffers, 2...    668-ca. 631   \n","Q009297  Created by Jamie Novotny and Joshua Jeffers, 2...    668-ca. 631   \n","Q009298  Created by Jamie Novotny and Joshua Jeffers, 2...    668-ca. 631   \n","Q009503  Created by Jamie Novotny, 2022. Lemmatized by ...    ca. 626-612   \n","\n","                    designation          display_name dynastic_seat  \\\n","Q003414  Tiglath-pileser III 01  RINAP 1 Tigl. III 01       Assyria   \n","Q003415  Tiglath-pileser III 02  RINAP 1 Tigl. III 02       Assyria   \n","Q003416  Tiglath-pileser III 03  RINAP 1 Tigl. III 03       Assyria   \n","Q003417  Tiglath-pileser III 04  RINAP 1 Tigl. III 04       Assyria   \n","Q003418  Tiglath-pileser III 05  RINAP 1 Tigl. III 05       Assyria   \n","...                         ...                   ...           ...   \n","Q009295       Ashurbanipal 1027     RINAP 5 Asb. 1027       Assyria   \n","Q009296       Ashurbanipal 1028     RINAP 5 Asb. 1028       Assyria   \n","Q009297       Ashurbanipal 1029     RINAP 5 Asb. 1029       Assyria   \n","Q009298       Ashurbanipal 1030     RINAP 5 Asb. 1030       Assyria   \n","Q009503    Sîn-šarru-iškun 2001      RINAP 5 Ssi 2001       Assyria   \n","\n","                                              exemplars  ...  \\\n","Q003414  ZhArchSlg 1917 (+) ZhArchSlg 1918 (+) NA 12/76  ...   \n","Q003415                                        NA 12/76  ...   \n","Q003416                                        NA 09/76  ...   \n","Q003417                                        NA 09/76  ...   \n","Q003418            BM 118934 (Layard, MS A pp. 113-114)  ...   \n","...                                                 ...  ...   \n","Q009295                                         K 06681  ...   \n","Q009296                                         K 06806  ...   \n","Q009297                             Bu 1891-05-09, 0204  ...   \n","Q009298                    Shikaft-i Gulgul rock relief  ...   \n","Q009503                                1855-12-05, 0252  ...   \n","\n","                       ruler                        script script_remarks  \\\n","Q003414  Tiglath-pileser III                  Neo-Assyrian      inscribed   \n","Q003415  Tiglath-pileser III                  Neo-Assyrian      inscribed   \n","Q003416  Tiglath-pileser III                  Neo-Assyrian      inscribed   \n","Q003417  Tiglath-pileser III                  Neo-Assyrian      inscribed   \n","Q003418  Tiglath-pileser III                  Neo-Assyrian      inscribed   \n","...                      ...                           ...            ...   \n","Q009295         Ashurbanipal                  Neo-Assyrian      inscribed   \n","Q009296         Ashurbanipal                  Neo-Assyrian      inscribed   \n","Q009297         Ashurbanipal                  Neo-Assyrian      inscribed   \n","Q009298         Ashurbanipal  Neo-Assyrian, Neo-Babylonian      inscribed   \n","Q009503      Sîn-šarru-iškun                  Neo-Assyrian      inscribed   \n","\n","        script_type             subgenre supergenre   trans id_text seal_id  \\\n","Q003414   Cuneiform  Tiglath-pileser III        LIT  ['en']                   \n","Q003415   Cuneiform  Tiglath-pileser III        LIT  ['en']                   \n","Q003416   Cuneiform  Tiglath-pileser III        LIT  ['en']                   \n","Q003417   Cuneiform  Tiglath-pileser III        LIT  ['en']                   \n","Q003418   Cuneiform  Tiglath-pileser III        LIT  ['en']                   \n","...             ...                  ...        ...     ...     ...     ...   \n","Q009295   Cuneiform         Ashurbanipal        LIT  ['en']                   \n","Q009296   Cuneiform         Ashurbanipal        LIT  ['en']                   \n","Q009297   Cuneiform         Ashurbanipal        LIT  ['en']                   \n","Q009298   Cuneiform         Ashurbanipal        LIT  ['en']                   \n","Q009503   Cuneiform      Sîn-šarru-iškun        LIT  ['en']                   \n","\n","                                               attribution  \n","Q003414                                                     \n","Q003415                                                     \n","Q003416                                                     \n","Q003417                                                     \n","Q003418                                                     \n","...                                                    ...  \n","Q009295  Created by Jamie Novotny and Joshua Jeffers, 2...  \n","Q009296  Created by Jamie Novotny and Joshua Jeffers, 2...  \n","Q009297  Created by Jamie Novotny and Joshua Jeffers, 2...  \n","Q009298  Created by Jamie Novotny and Joshua Jeffers, 2...  \n","Q009503  Created by Jamie Novotny, 2022. Lemmatized by ...  \n","\n","[432 rows x 31 columns]"],"text/html":["\n","  <div id=\"df-66ca47d0-0b62-4b44-aa1a-3e945326e2f1\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>langs</th>\n","      <th>project</th>\n","      <th>cdli_id</th>\n","      <th>collection</th>\n","      <th>credits</th>\n","      <th>date_of_origin</th>\n","      <th>designation</th>\n","      <th>display_name</th>\n","      <th>dynastic_seat</th>\n","      <th>exemplars</th>\n","      <th>...</th>\n","      <th>ruler</th>\n","      <th>script</th>\n","      <th>script_remarks</th>\n","      <th>script_type</th>\n","      <th>subgenre</th>\n","      <th>supergenre</th>\n","      <th>trans</th>\n","      <th>id_text</th>\n","      <th>seal_id</th>\n","      <th>attribution</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Q003414</th>\n","      <td>0x08000000</td>\n","      <td>rinap/rinap1</td>\n","      <td>P463047</td>\n","      <td>Archäologisches Institut der Universität Züric...</td>\n","      <td>Created by Hayim Tadmor, Shigeo Yamada, Jamie ...</td>\n","      <td>744-727</td>\n","      <td>Tiglath-pileser III 01</td>\n","      <td>RINAP 1 Tigl. III 01</td>\n","      <td>Assyria</td>\n","      <td>ZhArchSlg 1917 (+) ZhArchSlg 1918 (+) NA 12/76</td>\n","      <td>...</td>\n","      <td>Tiglath-pileser III</td>\n","      <td>Neo-Assyrian</td>\n","      <td>inscribed</td>\n","      <td>Cuneiform</td>\n","      <td>Tiglath-pileser III</td>\n","      <td>LIT</td>\n","      <td>['en']</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>Q003415</th>\n","      <td>0x08000000</td>\n","      <td>rinap/rinap1</td>\n","      <td>P463047</td>\n","      <td></td>\n","      <td>Created by Hayim Tadmor, Shigeo Yamada, Jamie ...</td>\n","      <td>744-727</td>\n","      <td>Tiglath-pileser III 02</td>\n","      <td>RINAP 1 Tigl. III 02</td>\n","      <td>Assyria</td>\n","      <td>NA 12/76</td>\n","      <td>...</td>\n","      <td>Tiglath-pileser III</td>\n","      <td>Neo-Assyrian</td>\n","      <td>inscribed</td>\n","      <td>Cuneiform</td>\n","      <td>Tiglath-pileser III</td>\n","      <td>LIT</td>\n","      <td>['en']</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>Q003416</th>\n","      <td>0x08000000</td>\n","      <td>rinap/rinap1</td>\n","      <td>P463048</td>\n","      <td></td>\n","      <td>Created by Hayim Tadmor, Shigeo Yamada, Jamie ...</td>\n","      <td>744-727</td>\n","      <td>Tiglath-pileser III 03</td>\n","      <td>RINAP 1 Tigl. III 03</td>\n","      <td>Assyria</td>\n","      <td>NA 09/76</td>\n","      <td>...</td>\n","      <td>Tiglath-pileser III</td>\n","      <td>Neo-Assyrian</td>\n","      <td>inscribed</td>\n","      <td>Cuneiform</td>\n","      <td>Tiglath-pileser III</td>\n","      <td>LIT</td>\n","      <td>['en']</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>Q003417</th>\n","      <td>0x08000000</td>\n","      <td>rinap/rinap1</td>\n","      <td>P463048</td>\n","      <td></td>\n","      <td>Created by Hayim Tadmor, Shigeo Yamada, Jamie ...</td>\n","      <td>744-727</td>\n","      <td>Tiglath-pileser III 04</td>\n","      <td>RINAP 1 Tigl. III 04</td>\n","      <td>Assyria</td>\n","      <td>NA 09/76</td>\n","      <td>...</td>\n","      <td>Tiglath-pileser III</td>\n","      <td>Neo-Assyrian</td>\n","      <td>inscribed</td>\n","      <td>Cuneiform</td>\n","      <td>Tiglath-pileser III</td>\n","      <td>LIT</td>\n","      <td>['en']</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>Q003418</th>\n","      <td>0x08000000</td>\n","      <td>rinap/rinap1</td>\n","      <td>P463049</td>\n","      <td>British Museum, London, UK</td>\n","      <td>Created by Hayim Tadmor, Shigeo Yamada, Jamie ...</td>\n","      <td>744-727</td>\n","      <td>Tiglath-pileser III 05</td>\n","      <td>RINAP 1 Tigl. III 05</td>\n","      <td>Assyria</td>\n","      <td>BM 118934 (Layard, MS A pp. 113-114)</td>\n","      <td>...</td>\n","      <td>Tiglath-pileser III</td>\n","      <td>Neo-Assyrian</td>\n","      <td>inscribed</td>\n","      <td>Cuneiform</td>\n","      <td>Tiglath-pileser III</td>\n","      <td>LIT</td>\n","      <td>['en']</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>Q009295</th>\n","      <td>0x08000000</td>\n","      <td>rinap/rinap5</td>\n","      <td></td>\n","      <td>British Museum, London, UK</td>\n","      <td>Created by Jamie Novotny and Joshua Jeffers, 2...</td>\n","      <td>668-ca. 631</td>\n","      <td>Ashurbanipal 1027</td>\n","      <td>RINAP 5 Asb. 1027</td>\n","      <td>Assyria</td>\n","      <td>K 06681</td>\n","      <td>...</td>\n","      <td>Ashurbanipal</td>\n","      <td>Neo-Assyrian</td>\n","      <td>inscribed</td>\n","      <td>Cuneiform</td>\n","      <td>Ashurbanipal</td>\n","      <td>LIT</td>\n","      <td>['en']</td>\n","      <td></td>\n","      <td></td>\n","      <td>Created by Jamie Novotny and Joshua Jeffers, 2...</td>\n","    </tr>\n","    <tr>\n","      <th>Q009296</th>\n","      <td>0x08000000</td>\n","      <td>rinap/rinap5</td>\n","      <td></td>\n","      <td>British Museum, London, UK</td>\n","      <td>Created by Jamie Novotny and Joshua Jeffers, 2...</td>\n","      <td>668-ca. 631</td>\n","      <td>Ashurbanipal 1028</td>\n","      <td>RINAP 5 Asb. 1028</td>\n","      <td>Assyria</td>\n","      <td>K 06806</td>\n","      <td>...</td>\n","      <td>Ashurbanipal</td>\n","      <td>Neo-Assyrian</td>\n","      <td>inscribed</td>\n","      <td>Cuneiform</td>\n","      <td>Ashurbanipal</td>\n","      <td>LIT</td>\n","      <td>['en']</td>\n","      <td></td>\n","      <td></td>\n","      <td>Created by Jamie Novotny and Joshua Jeffers, 2...</td>\n","    </tr>\n","    <tr>\n","      <th>Q009297</th>\n","      <td>0x08000000</td>\n","      <td>rinap/rinap5</td>\n","      <td></td>\n","      <td>British Museum, London, UK</td>\n","      <td>Created by Jamie Novotny and Joshua Jeffers, 2...</td>\n","      <td>668-ca. 631</td>\n","      <td>Ashurbanipal 1029</td>\n","      <td>RINAP 5 Asb. 1029</td>\n","      <td>Assyria</td>\n","      <td>Bu 1891-05-09, 0204</td>\n","      <td>...</td>\n","      <td>Ashurbanipal</td>\n","      <td>Neo-Assyrian</td>\n","      <td>inscribed</td>\n","      <td>Cuneiform</td>\n","      <td>Ashurbanipal</td>\n","      <td>LIT</td>\n","      <td>['en']</td>\n","      <td></td>\n","      <td></td>\n","      <td>Created by Jamie Novotny and Joshua Jeffers, 2...</td>\n","    </tr>\n","    <tr>\n","      <th>Q009298</th>\n","      <td>0x08000000</td>\n","      <td>rinap/rinap5</td>\n","      <td></td>\n","      <td></td>\n","      <td>Created by Jamie Novotny and Joshua Jeffers, 2...</td>\n","      <td>668-ca. 631</td>\n","      <td>Ashurbanipal 1030</td>\n","      <td>RINAP 5 Asb. 1030</td>\n","      <td>Assyria</td>\n","      <td>Shikaft-i Gulgul rock relief</td>\n","      <td>...</td>\n","      <td>Ashurbanipal</td>\n","      <td>Neo-Assyrian, Neo-Babylonian</td>\n","      <td>inscribed</td>\n","      <td>Cuneiform</td>\n","      <td>Ashurbanipal</td>\n","      <td>LIT</td>\n","      <td>['en']</td>\n","      <td></td>\n","      <td></td>\n","      <td>Created by Jamie Novotny and Joshua Jeffers, 2...</td>\n","    </tr>\n","    <tr>\n","      <th>Q009503</th>\n","      <td>0x08000000</td>\n","      <td>rinap/rinap5</td>\n","      <td></td>\n","      <td>British Museum, London, UK</td>\n","      <td>Created by Jamie Novotny, 2022. Lemmatized by ...</td>\n","      <td>ca. 626-612</td>\n","      <td>Sîn-šarru-iškun 2001</td>\n","      <td>RINAP 5 Ssi 2001</td>\n","      <td>Assyria</td>\n","      <td>1855-12-05, 0252</td>\n","      <td>...</td>\n","      <td>Sîn-šarru-iškun</td>\n","      <td>Neo-Assyrian</td>\n","      <td>inscribed</td>\n","      <td>Cuneiform</td>\n","      <td>Sîn-šarru-iškun</td>\n","      <td>LIT</td>\n","      <td>['en']</td>\n","      <td></td>\n","      <td></td>\n","      <td>Created by Jamie Novotny, 2022. Lemmatized by ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>432 rows × 31 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-66ca47d0-0b62-4b44-aa1a-3e945326e2f1')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-66ca47d0-0b62-4b44-aa1a-3e945326e2f1 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-66ca47d0-0b62-4b44-aa1a-3e945326e2f1');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-43130423-04a1-42f3-8ff9-336fd785c6f5\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-43130423-04a1-42f3-8ff9-336fd785c6f5')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-43130423-04a1-42f3-8ff9-336fd785c6f5 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_33537c72-91df-4deb-aada-298ccb6af594\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('metadata')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_33537c72-91df-4deb-aada-298ccb6af594 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('metadata');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"metadata"}},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["### To convert dataframe to string"],"metadata":{"id":"LD-SVUMViYnS"}},{"cell_type":"markdown","source":["**Function to split the text dataframes according to a column**. Used to separate text to lines:\n","* param df: dataframe containing one word in each row.\n","* param column: the column by which to split the dfs, perferably `text` or `line`.\n","* return: a list of dataframes split according to the value given to the column parameter.\n","\n"],"metadata":{"id":"ICeHGzO7h1tn"}},{"cell_type":"code","source":["def split_df_by_column_value(df, column):\n","\n","    dfs = []\n","    column_values = df[column].unique()\n","    for value in column_values:\n","        split_df = df[df[column]==value]\n","        dfs.append(split_df)\n","    return dfs"],"metadata":{"id":"F6QGuzdwiCXe","executionInfo":{"status":"ok","timestamp":1737385870170,"user_tz":-120,"elapsed":203,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["split_df_by_column_value(corpus[0].head(), \"line\")"],"metadata":{"id":"mxoSOTE_jKTA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1737385872988,"user_tz":-120,"elapsed":244,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}},"outputId":"4941d099-ad46-4e53-f144-1f4362b3728a"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[              ref                          inst         frag    norm      cf  \\\n"," 9515  Q003414.2.1  perʾu[bud//offspring]N$perʾi        NUNUZ   perʾi   perʾu   \n"," 9516  Q003414.2.2               Baltil[Aššur]QN  bal-til{ki}  Baltil  Baltil   \n"," 9517  Q003414.2.3       šūquru[very valuable]AJ   šu-⸢qu-ru⸣  šūquru  šūquru   \n"," 9518  Q003414.2.4             narām[loved one]N       na-ram   narām  narāmu   \n"," 9519  Q003414.2.5                             u    {d}[(...)                   \n"," \n","               sense pos          unicode unicode_word      reading  \\\n"," 9515      offspring   N            ['𒉭']            𒉭        NUNUZ   \n"," 9516          Aššur  QN  ['𒁄', '𒌀', '𒆠']          𒁄𒌀𒆠  bal-til{KI}   \n"," 9517  very valuable  AJ  ['𒋗', '𒄣', '𒊒']          𒋗𒄣𒊒   šu-⸢qu-ru⸣   \n"," 9518      loved one   N       ['𒈾', '𒉘']           𒈾𒉘       na-ram   \n"," 9519                  u       ['𒀭', 'x']           𒀭x       {d}[x]   \n"," \n","                                      break  break_perc mask lang     text  \\\n"," 9515                          ['complete']        0.00            Q003414   \n"," 9516  ['complete', 'complete', 'complete']        0.00            Q003414   \n"," 9517    ['complete', 'damaged', 'damaged']        0.33            Q003414   \n"," 9518              ['complete', 'complete']        0.00            Q003414   \n"," 9519               ['complete', 'missing']        0.50            Q003414   \n"," \n","       line  word  \n"," 9515     2     1  \n"," 9516     2     2  \n"," 9517     2     3  \n"," 9518     2     4  \n"," 9519     2     5  ]"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["**Function to convert the values from the text dataframe to a string of text with or without line breaks and word segmentation**.\n","* param df: the text dataframe\n","* param column: the chosen column from the dataframe to construct the text from (preferably unicode_word, cf, or lemma)\n","* param break_perc: a parameter which dictates whether to include broken words depending on the percentage of how broken they are.\n","                       Compares this value to the `break_perc` column in the dataframe.\n","                       Parameter is set to 1 (i.e. all words, whether broken or not, are included); can be any float between 0 and 1.\n","* param mask: boolean whether to mask named entities or not; set to True.\n","* return: a string which includes all the words in the texts according to the column chosen. Extra spaces that were between broken words or empty lines are removed."],"metadata":{"id":"245HmRQRihqM"}},{"cell_type":"code","source":["def df2str(df, column, break_perc=1, mask=True, segmentation=True):\n","\n","    # check if column exists in dataframe. If not, return empty text.\n","    if column not in df.columns:\n","        return (\"\", 0, 0)\n","    else:\n","        # remove rows that include duplicate values for compound words\n","        if column not in [\"norm\", \"cf\", \"sense\", \"pos\"]:\n","            df = df.drop_duplicates(\"ref\").copy()\n","        # if column entry is empty string, replace with UNK (can happen with normalization or lemmatization)\n","        mask_empty = df[column]==\"\"\n","        df[column] = df[column].where(~mask_empty, other=\"UNK\")\n","        # mask proper nouns\n","        if mask and \"pos\" in df.columns:\n","            mask_bool = df[\"pos\"].isin([\"PN\", \"RN\", \"DN\", \"GN\", \"MN\", \"SN\", \"n\"])\n","            df[column] = df[column].where(~mask_bool, other=df[\"pos\"])\n","\n","        # change number masking from `n` to `NUM`\n","        # !comment out for Egyptian\n","        #if mask:\n","        #    mask_num = df[column]==\"n\"\n","        #    df[column] = df[column].where(~mask_num, other=\"NUM\")\n","\n","        # remove rows without break_perc (happens with non-Akkadian words)\n","        if \"\" in df[\"break_perc\"].unique():\n","            df = df[df[\"break_perc\"]!=\"\"].copy()\n","        # filter according to break_perc\n","        mask_break = df[\"break_perc\"] <= break_perc\n","        df[column] = df[column].where(mask_break, other=\"X\")\n","        # calculate text length with and without UNK and x tokens\n","        text_length_full = df.shape[0]\n","        mask_partial = df[column].isin([\"UNK\", \"X\", \"x\"])\n","        text_length_partial = text_length_full - sum(mask_partial)\n","        # create text lines\n","        text = \"\"\n","        df_lines = split_df_by_column_value(df, \"line\")\n","        for line in df_lines:\n","            word_list = list(filter(None, line[column].to_list()))\n","            if word_list != []:\n","                text += \" \".join(map(str, word_list)).replace(\"x\", \"X\").strip() + \"\\n\"\n","\n","        if segmentation == False:\n","            # remove all white spaces (word segmentation and line breaks)\n","            text = re.sub(r\"[\\s\\u00A0]+\", \"\", text)\n","\n","        return (text, text_length_full, text_length_partial)"],"metadata":{"id":"ZhXsDitEiu9P","executionInfo":{"status":"ok","timestamp":1737385878197,"user_tz":-120,"elapsed":217,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["df2str(corpus[0], \"cf\")"],"metadata":{"id":"QkUpMMp5jIKQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1737385882504,"user_tz":-120,"elapsed":209,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}},"outputId":"f902b177-eb42-4773-90c1-8c33f63998a3"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('perʾu Baltil šūquru narāmu UNK DN UNK UNK UNK UNK\\npitqu DN ša ana bēlūtu mātu UNK UNK UNK UNK UNK UNK\\nrabû ana šarrūtu šakkanakku UNK UNK UNK UNK UNK UNK\\nmuṣṣibu šagigurrû ana UNK UNK UNK UNK UNK UNK UNK UNK šurīnu\\nzikaru dannu nūru kiššatu nišu etellu UNK kalû malku UNK UNK UNK\\ndāʾipu gērû eṭlu qardu sāpinu UNK nakru ša huršānu\\netguru kīma qû salātu UNK UNK UNK UNK UNK UNK\\n',\n"," 75,\n"," 39)"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["### To convert to specific word levels and create dictionaries"],"metadata":{"id":"-UGZ10MnjEG5"}},{"cell_type":"markdown","source":["**Function to convert the dataframes into strings of lemmatized texts**.\n","* param corpus: a list of dataframes\n","* param break_perc: a parameter which dictates whether to include broken words depending on the percentage of how broken they are.\n","                       Compares this value to the `break_perc` column in the dataframe.\n","                       Parameter is set to 1 (i.e. all words, whether broken or not, are included); can be any float between 0 and 1.\n","* param mask: boolean whether to mask named entities or not; set to True.\n","* return: a dictionary where the keys are the text IDs and the values are the lemmatized texts"],"metadata":{"id":"IWIlEgvZCGGO"}},{"cell_type":"code","source":["def get_lemmatized_texts(corpus, break_perc=1, mask=True):\n","\n","    texts_dict = {}\n","    for df in corpus:\n","        # get the text number from the dataframe \"text\" column\n","        key = df[\"text\"].iloc[0]\n","        text, text_length_full, text_length_partial = df2str(df, \"lemma_id\", break_perc, mask)\n","        texts_dict[key] = (text, text_length_full, text_length_partial)\n","    return texts_dict"],"metadata":{"id":"KjEVlACkBtBi","executionInfo":{"status":"ok","timestamp":1737385891992,"user_tz":-120,"elapsed":237,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["get_lemmatized_texts((split_df_by_column_value(corpus[0], \"text\")))"],"metadata":{"id":"6Bl6MhgICuFK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1737385894401,"user_tz":-120,"elapsed":227,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}},"outputId":"e434dd03-2047-43a0-80f0-21724dc186a0"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Q003414': ('', 0, 0)}"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["**Function to convert the dataframes into strings of normalized texts**.\n","* param corpus: a list of dataframes\n","* param break_perc: a parameter which dictates whether to include broken words depending on the percentage of how broken they are.\n","                       Compares this value to the `break_perc` column in the dataframe.\n","                       Parameter is set to 1 (i.e. all words, whether broken or not, are included); can be any float between 0 and 1.\n","* param mask: boolean whether to mask named entities or not; set to True.\n","* return: a dictionary where the keys are the text IDs and the values are the normalized texts"],"metadata":{"id":"cU-mpEjFDlLx"}},{"cell_type":"code","source":["def get_normalized_texts(corpus, break_perc=1, mask=True):\n","\n","    texts_dict = {}\n","    for df in corpus:\n","        # get the text number from the dataframe \"text\" column\n","        key = df[\"text\"].iloc[0]\n","        text, text_length_full, text_length_partial = df2str(df, \"norm\", break_perc, mask)\n","        texts_dict[key] = (text, text_length_full, text_length_partial)\n","    return texts_dict"],"metadata":{"id":"2iJAkjhUDuDy","executionInfo":{"status":"ok","timestamp":1737385908202,"user_tz":-120,"elapsed":389,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["get_normalized_texts((split_df_by_column_value(corpus[0], \"text\")))"],"metadata":{"id":"7cJpNzRvDyFu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1737385910671,"user_tz":-120,"elapsed":240,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}},"outputId":"91608813-d005-43df-93b7-14c0847e135a"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Q003414': ('perʾi Baltil šūquru narām UNK DN UNK UNK UNK UNK\\npitiq DN ša ana bēlūt mātāti UNK UNK UNK UNK UNK UNK\\nirbû ana šarrūti šakkanakku UNK UNK UNK UNK UNK UNK\\nmuṣṣib šagigurê ana UNK UNK UNK UNK UNK UNK UNK UNK šurinnī\\nzikaru dannu nūr kiššat nišīšu etel UNK kal malkī UNK UNK UNK\\ndāʾipu gārêšu eṭlu qardu sāpinu UNK nakiri ša hursānī\\netgurūti kīma qê usallituma UNK UNK UNK UNK UNK UNK\\n',\n","  75,\n","  39)}"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["**Function to convert the dataframes into strings of segmented unicode texts**.\n","* param corpus: a list of dataframes\n","* param break_perc: a parameter which dictates whether to include broken words depending on the percentage of how broken they are.\n","                       Compares this value to the `break_perc` column in the dataframe.\n","                       Parameter is set to 1 (i.e. all words, whether broken or not, are included); can be any float between 0 and 1.\n","* param mask: boolean whether to mask named entities or not; set to True.\n","* return: a dictionary where the keys are the text IDs and the values are the segmented unicode texts"],"metadata":{"id":"51W1Q2EmEg5N"}},{"cell_type":"code","source":["def get_segmented_unicode_texts(corpus, break_perc=1, mask=True):\n","\n","    texts_dict = {}\n","    for df in corpus:\n","        # get the text number from the dataframe \"text\" column\n","        key = df[\"text\"].iloc[0]\n","        text, text_length_full, text_length_partial = df2str(df, \"unicode_word\", break_perc, mask)\n","        texts_dict[key] = (text, text_length_full, text_length_partial)\n","    return texts_dict"],"metadata":{"id":"68fqoZrdEggT","executionInfo":{"status":"ok","timestamp":1737385919838,"user_tz":-120,"elapsed":228,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["get_segmented_unicode_texts((split_df_by_column_value(corpus[0], \"text\")))"],"metadata":{"id":"XKUSmEOaE8sE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1737385921874,"user_tz":-120,"elapsed":220,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}},"outputId":"5d2b7373-ffe3-495e-c6d8-b54c95131def"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Q003414': ('𒉭 𒁄𒌀𒆠 𒋗𒄣𒊒 𒈾𒉘 𒀭X DN 𒀊 𒁀 X X\\n𒉿𒄘 DN 𒃻 𒀀𒈾 𒁁𒂁 𒆳𒆳 X 𒀭 𒋾 𒀠 𒋃 X\\n𒅕𒁍𒌑 𒀀𒈾 𒈗𒌑𒋾 𒄊𒀴 X X X X X 𒈠\\n𒈬𒍦 𒊮𒅆𒃸𒎌 𒀀𒈾 X X X X X X X X 𒋗𒊑𒅔𒉌\\n𒍣𒅗𒊒 𒆗𒉡 𒉡𒌨 𒆧𒆳 𒌦𒎌𒋗 𒂊𒌀 X 𒆗 𒂷𒆠 X X 𒋾\\n𒁕𒄿𒁍 𒂵𒊑𒂊𒋗 𒄨 𒃼𒁺 𒊓𒉿𒉡 X 𒈾𒆠𒊑 𒃻 𒄯𒊓𒀀𒉌\\n𒀉𒄖𒊒𒋾 𒆠𒈠 𒆠𒂊 𒌑𒊩𒇷𒌅𒈠 𒌑X 𒌑 X X X X\\n',\n","  75,\n","  50)}"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["### To create the vector space model"],"metadata":{"id":"PMCMiNQE5kbj"}},{"cell_type":"markdown","source":["#### vectorizing texts"],"metadata":{"id":"s9ioJeo0KqOn"}},{"cell_type":"markdown","source":["**Converts a list of texts into a term-document matrix based on TF-IDF scores**.\n","\n","Full documentation of the variables of TfidfVectorizer from sklearn, see: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer\n","* param corpus: a dataframe in which the texts are in a `\"text\"` column and the dataframe's index is the text ids.\n","* param analyzer: whether the feature should be made of word or character n-grams.\n","                     use `\"word\"` for word features, `\"char_wb\"` for character n-grams within word boundaries,\n","                     or `\"char\"` for character n-grams without word boundaries.\n","* param ngram_range: the lower and upper boundary of the range of n-values for different n-grams to be extracted.\n","* param max_df: threshold to ignore terms that have a document frequency above a certain value.\n","                   If the threshold is a float, it represent a proportion of the documents.\n","                   If the threshold is an integer, it represents absolute counts of number of documents in which the terms appears.\n","* param min_df: threshold to ignore terms that have a document frequency below a certain value.\n","                   If the threshold is a float, it represent a proportion of the documents.\n","                   If the threshold is an integer, it represents absolute counts of number of documents in which the terms appears.\n","* param max_features: if not `None`, build a vocabulary that only considers the top max_features ordered by term frequency across the corpus.\n","* param stop_words: if `None`, no stop words are used. Otherwise, can be a list with words to be removed from resulting tokens.\n","* return: `counts` the raw counts of the vectorizer,\n","             `counts_df` a dataframe of the counts where the index is the text ids and the columns are the tokens,\n","             `stop_words` an updated list of stop words"],"metadata":{"id":"jVN9XLRlJ9D8"}},{"cell_type":"markdown","source":["![](https://www.humanitiesdataanalysis.org/_images/bow.png)\n","\n"],"metadata":{"id":"nJquCdqxOwrn"}},{"cell_type":"markdown","source":["**Figure 1**. Example of a document-term matrix extracted from a corpus, see Fig. 3 in Karsdorp, F., Kestemont, M., & Riddell, A. (2021). Humanities Data Analysis: Case Studies\n","with Python. Princeton University Press."],"metadata":{"id":"m1ZSucGrQpE1"}},{"cell_type":"code","source":["def vectorize(corpus, analyzer=\"word\", ngram_range=(1,1), max_df=1.0, min_df=1, max_features=None, stop_words=[\"UNK\", \"X\"]):\n","\n","    vectorizer = TfidfVectorizer(input=\"content\", lowercase=False, analyzer=analyzer,\n","                                 # RegEx for Akkadian\n","                                 #token_pattern=r\"(?u)\\b\\w+\\b\", ngram_range=ngram_range,\n","                                 # RegEx for Egyptian\n","                                 token_pattern=r\"(?u)\\b[\\w\\.]+\\b\", ngram_range=ngram_range,\n","                                 max_df=max_df, min_df=min_df, max_features=max_features, stop_words=stop_words)\n","\n","    counts = vectorizer.fit_transform(corpus[\"text\"].tolist()).toarray()\n","    stop_words = vectorizer.stop_words_\n","\n","    # saving the vocab used for vectorization, and switching the dictionary so that the feature index is the key\n","    vocab = vectorizer.vocabulary_\n","    switched_vocab = {value: key for key, value in vocab.items()}\n","    # adding the vocab words to the counts dataframe for easier viewing.\n","    column_names = []\n","    x = 0\n","    while x < len(switched_vocab):\n","        column_names.append(switched_vocab[x])\n","        x += 1\n","\n","    counts_df = pd.DataFrame(counts, index=corpus.index, columns=column_names)\n","\n","    return (counts, counts_df, stop_words)"],"metadata":{"id":"ekWEVWPrK1B-","executionInfo":{"status":"ok","timestamp":1737385929859,"user_tz":-120,"elapsed":212,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["#### calculating distances between vectorized documents"],"metadata":{"id":"M38qD4s0K9tv"}},{"cell_type":"markdown","source":["**Converts a term-document matrix to a text similarity matrix**.\n","* param counts: the raw counts from the `vectorize` function.\n","* param metric: the metric by which to calculate the distances between the texts in the corpus. For one place to look into the different types of matrics see \"Computing distances between documents\" in [Karsdrop, Kestemont, & Riddell 2021](https://www.humanitiesdataanalysis.org/vector-space-model/notebook.html#computing-distances-between-documents)\n","                   Valid metrics are:\n","                   ‘braycurtis’, ‘canberra’, ‘chebyshev’, ‘cityblock’, ‘correlation’, ‘cosine’,\n","                   ‘dice’, ‘euclidean’, ‘hamming’, ‘jaccard’, ‘jensenshannon’, ‘kulczynski1’,\n","                   ‘mahalanobis’, ‘matching’, ‘minkowski’, ‘rogerstanimoto’, ‘russellrao’,\n","                   ‘seuclidean’, ‘sokalmichener’, ‘sokalsneath’, ‘sqeuclidean’, ‘yule’.\n","* param text_ids: list of unique text_ids.\n","* return: a dataframe matrix of distance between texts."],"metadata":{"id":"9LuEi5HRLEWY"}},{"cell_type":"code","source":["def distance_calculator(counts, metric, text_ids):\n","\n","    return pd.DataFrame(squareform(pdist(counts, metric=metric)), index=text_ids, columns=text_ids)"],"metadata":{"id":"JtgbjirqLDjG","executionInfo":{"status":"ok","timestamp":1737385934962,"user_tz":-120,"elapsed":202,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["#### reducing dimensions with pca or tsne"],"metadata":{"id":"3oFCyz3rLasY"}},{"cell_type":"markdown","source":["**Reduces multidimensional data into two dimensions using PCA**.\n","* param df: dataframe holding the dimensions to reduce. All columns should include numerical values only.\n","               The dataframe's index should hold the unique text ids.\n","* param metadata: the rest of the metadata in the corpus, to help visualize the resulting clusters in meaningful ways.\n","                     The metadata's index should hold the unique text ids.\n","* return: a dataframe with the coordinates of the two remaining dimensions on all other columns from the metadata."],"metadata":{"id":"J-CdhqfwLjhF"}},{"cell_type":"code","source":["def reduce_dimensions_pca(df, metadata):\n","\n","    pca = PCA(n_components=2)\n","    reduced_data = pca.fit_transform(df)\n","    reduced_df = pd.DataFrame(data=reduced_data, index=df.index, columns=[\"component 1\", \"component 2\"])\n","    reduced_df_metadata = metadata.join(reduced_df)\n","    return reduced_df_metadata"],"metadata":{"id":"Sn1l5Rp_Lbac","executionInfo":{"status":"ok","timestamp":1737385939211,"user_tz":-120,"elapsed":211,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":["**Reduces multidimensional data into two dimensions using TSNE**.\n","\n","See full documentation of sklearn's TSNE on: https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html\n","* param df: dataframe holding the dimensions to reduce. All columns should include numerical values only.\n","               The dataframe's index should hold the unique text ids.\n","* param perplexity: perplexity is a measure the weighs the importance of nearby versus distant points when creating a lower-dimension mapping.\n","                       t-SNE first converts the distances between points into conditional probabilities that represent similarities,\n","                       using Gaussian probability distributions.\n","                       The perplexity parameter influences the variance used to compute these probabilities.\n","                       A higher perplexity leads to a broader Gaussian that considers a larger number of neighbors when assessing similarity.\n","                       Lower perplexity puts more focus on the local structure and considers fewer neighbors.\n","                       A good perplexity depends greatly on dataset size and density.\n","                       The documentation recommends a value between 5 and 50.\n","                       We recommend to start with the square root of the length of the corpus.\n","* param n_iter: maximum number of iterations for optimization.\n","* param metric: the metric to be used when calculating distances between vectors.\n","                   Valid metrics are:\n","                   ‘braycurtis’, ‘canberra’, ‘chebyshev’, ‘cityblock’, ‘correlation’, ‘cosine’,\n","                   ‘dice’, ‘euclidean’, ‘hamming’, ‘jaccard’, ‘jensenshannon’, ‘kulczynski1’,\n","                   ‘mahalanobis’, ‘matching’, ‘minkowski’, ‘rogerstanimoto’, ‘russellrao’,\n","                   ‘seuclidean’, ‘sokalmichener’, ‘sokalsneath’, ‘sqeuclidean’, ‘yule’.\n","* param metadata: the rest of the metadata in the corpus, to help visualize the resulting clusters in meaningful ways.\n","                     The metadata's index should hold the unique text ids.\n","* return: a dataframe with the coordinates of the two remaining dimensions on all other columns from the metadata."],"metadata":{"id":"fvp4qrkULy6a"}},{"cell_type":"code","source":["def reduce_dimensions_tsne(df, perplexity, n_iter, metric, metadata):\n","\n","    tsne = TSNE(n_components=2, perplexity=perplexity, n_iter=n_iter, metric=metric, init=\"pca\")\n","    reduced_data = tsne.fit_transform(df)\n","    reduced_df = pd.DataFrame(data=reduced_data, index=df.index, columns=[\"component 1\", \"component 2\"])\n","    reduced_df_metadata = metadata.join(reduced_df)\n","    return reduced_df_metadata"],"metadata":{"id":"BWEwUvt65p1f","executionInfo":{"status":"ok","timestamp":1737385945393,"user_tz":-120,"elapsed":223,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}}},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":["## Process texts from dataframes and combine results with metadata dataframe"],"metadata":{"id":"Jng_wsFahhjs"}},{"cell_type":"code","source":["# Function to combine processed texts with metadata\n","\n","def get_corpus_metadata(texts_dict, metadata):\n","  texts_df = pd.DataFrame(texts_dict, index=[\"text\", \"full_length\", \"partial_length\"]).transpose()\n","  df = metadata.join(texts_df)\n","  return df"],"metadata":{"id":"mWzJBzU7HJqm","executionInfo":{"status":"ok","timestamp":1737385949628,"user_tz":-120,"elapsed":226,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["## vectorize lemma forms\n","corpus_dict = get_lemmatized_texts(corpus, break_perc=0)\n","## vectorize normalized forms\n","corpus_dict = get_normalized_texts(corpus, break_perc=0)\n","## vectorize Unicode cuneiform\n","corpus_dict = get_segmented_unicode_texts(corpus, break_perc=0)\n","\n","corpus_metadata = get_corpus_metadata(corpus_dict, metadata)\n","\n","## For Akkadian\n","## remove texts which have less than n words excluding UNK and X\n","n = 10\n","print(f\"Number of texts before filtering: {corpus_metadata.shape[0]}\")\n","corpus_metadata = corpus_metadata[corpus_metadata[\"partial_length\"]>=n]\n","print(f\"Number of texts after filtering: {corpus_metadata.shape[0]}\")\n","\n","\n","# For Egyptian use this instead, reset the index\n","# n = 150\n","# print(f\"Number of texts before filtering: {corpus_metadata.shape[0]}\")\n","# corpus_metadata = corpus_metadata[corpus_metadata[\"partial_length\"]>=n].set_index(\"text_name\")\n","# print(f\"Number of texts after filtering: {corpus_metadata.shape[0]}\")"],"metadata":{"id":"Q1i9wtNCxJWJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1737386213592,"user_tz":-120,"elapsed":16204,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}},"outputId":"e173e0a1-a2df-483e-ce09-4309814181d2"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of texts before filtering: 432\n","Number of texts after filtering: 308\n"]}]},{"cell_type":"code","source":["corpus_metadata"],"metadata":{"id":"adGbPDc4FSwZ","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1737386217542,"user_tz":-120,"elapsed":271,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}},"outputId":"387010bf-f587-421c-8d39-272c51ccc8a7","collapsed":true},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["              langs       project  cdli_id  \\\n","Q003414  0x08000000  rinap/rinap1  P463047   \n","Q003417  0x08000000  rinap/rinap1  P463048   \n","Q003418  0x08000000  rinap/rinap1  P463049   \n","Q003419  0x08000000  rinap/rinap1  P463049   \n","Q003420  0x08000000  rinap/rinap1  P463050   \n","...             ...           ...      ...   \n","Q009293  0x08000000  rinap/rinap5            \n","Q009294  0x08000000  rinap/rinap5            \n","Q009295  0x08000000  rinap/rinap5            \n","Q009297  0x08000000  rinap/rinap5            \n","Q009298  0x08000000  rinap/rinap5            \n","\n","                                                collection  \\\n","Q003414  Archäologisches Institut der Universität Züric...   \n","Q003417                                                      \n","Q003418                         British Museum, London, UK   \n","Q003419                         British Museum, London, UK   \n","Q003420                         British Museum, London, UK   \n","...                                                    ...   \n","Q009293                         British Museum, London, UK   \n","Q009294                         British Museum, London, UK   \n","Q009295                         British Museum, London, UK   \n","Q009297                         British Museum, London, UK   \n","Q009298                                                      \n","\n","                                                   credits date_of_origin  \\\n","Q003414  Created by Hayim Tadmor, Shigeo Yamada, Jamie ...        744-727   \n","Q003417  Created by Hayim Tadmor, Shigeo Yamada, Jamie ...        744-727   \n","Q003418  Created by Hayim Tadmor, Shigeo Yamada, Jamie ...        744-727   \n","Q003419  Created by Hayim Tadmor, Shigeo Yamada, Jamie ...        744-727   \n","Q003420  Created by Hayim Tadmor, Shigeo Yamada, Jamie ...        744-727   \n","...                                                    ...            ...   \n","Q009293  Created by Jamie Novotny and Joshua Jeffers, 2...    668-ca. 631   \n","Q009294  Created by Jamie Novotny and Joshua Jeffers, 2...    668-ca. 631   \n","Q009295  Created by Jamie Novotny and Joshua Jeffers, 2...    668-ca. 631   \n","Q009297  Created by Jamie Novotny and Joshua Jeffers, 2...    668-ca. 631   \n","Q009298  Created by Jamie Novotny and Joshua Jeffers, 2...    668-ca. 631   \n","\n","                    designation          display_name dynastic_seat  \\\n","Q003414  Tiglath-pileser III 01  RINAP 1 Tigl. III 01       Assyria   \n","Q003417  Tiglath-pileser III 04  RINAP 1 Tigl. III 04       Assyria   \n","Q003418  Tiglath-pileser III 05  RINAP 1 Tigl. III 05       Assyria   \n","Q003419  Tiglath-pileser III 06  RINAP 1 Tigl. III 06       Assyria   \n","Q003420  Tiglath-pileser III 07  RINAP 1 Tigl. III 07       Assyria   \n","...                         ...                   ...           ...   \n","Q009293       Ashurbanipal 1025     RINAP 5 Asb. 1025       Assyria   \n","Q009294       Ashurbanipal 1026     RINAP 5 Asb. 1026       Assyria   \n","Q009295       Ashurbanipal 1027     RINAP 5 Asb. 1027       Assyria   \n","Q009297       Ashurbanipal 1029     RINAP 5 Asb. 1029       Assyria   \n","Q009298       Ashurbanipal 1030     RINAP 5 Asb. 1030       Assyria   \n","\n","                                              exemplars  ... script_type  \\\n","Q003414  ZhArchSlg 1917 (+) ZhArchSlg 1918 (+) NA 12/76  ...   Cuneiform   \n","Q003417                                        NA 09/76  ...   Cuneiform   \n","Q003418            BM 118934 (Layard, MS A pp. 113-114)  ...   Cuneiform   \n","Q003419                 BM 118934 (Layard, MS A p. 114)  ...   Cuneiform   \n","Q003420            BM 118933 (Layard, MS A pp. 111-112)  ...   Cuneiform   \n","...                                                 ...  ...         ...   \n","Q009293                                         K 04498  ...   Cuneiform   \n","Q009294                                         K 08361  ...   Cuneiform   \n","Q009295                                         K 06681  ...   Cuneiform   \n","Q009297                             Bu 1891-05-09, 0204  ...   Cuneiform   \n","Q009298                    Shikaft-i Gulgul rock relief  ...   Cuneiform   \n","\n","                    subgenre supergenre   trans id_text seal_id  \\\n","Q003414  Tiglath-pileser III        LIT  ['en']                   \n","Q003417  Tiglath-pileser III        LIT  ['en']                   \n","Q003418  Tiglath-pileser III        LIT  ['en']                   \n","Q003419  Tiglath-pileser III        LIT  ['en']                   \n","Q003420  Tiglath-pileser III        LIT  ['en']                   \n","...                      ...        ...     ...     ...     ...   \n","Q009293         Ashurbanipal        LIT  ['en']                   \n","Q009294         Ashurbanipal        LIT  ['en']                   \n","Q009295         Ashurbanipal        LIT  ['en']                   \n","Q009297         Ashurbanipal        LIT  ['en']                   \n","Q009298         Ashurbanipal        LIT  ['en']                   \n","\n","                                               attribution  \\\n","Q003414                                                      \n","Q003417                                                      \n","Q003418                                                      \n","Q003419                                                      \n","Q003420                                                      \n","...                                                    ...   \n","Q009293  Created by Jamie Novotny and Joshua Jeffers, 2...   \n","Q009294  Created by Jamie Novotny and Joshua Jeffers, 2...   \n","Q009295  Created by Jamie Novotny and Joshua Jeffers, 2...   \n","Q009297  Created by Jamie Novotny and Joshua Jeffers, 2...   \n","Q009298  Created by Jamie Novotny and Joshua Jeffers, 2...   \n","\n","                                                      text full_length  \\\n","Q003414  𒉭 𒁄𒌀𒆠 X 𒈾𒉘 X X 𒀊 𒁀 X X\\n𒉿𒄘 X 𒃻 𒀀𒈾 𒁁𒂁 X X 𒀭 𒋾 𒀠...          75   \n","Q003417  𒄿𒈾 𒊕 𒈗𒋾𒅀 𒄿𒈾 𒈤𒊑𒂊 𒁄𒅀 𒄿𒈾 n X\\n𒊭 𒄿𒈾 𒄑𒄖𒍝 𒈗𒌑𒋾 𒊏𒄫 𒌑𒅆𒁍...          37   \n","Q003418  X X 𒀀𒈾 𒆳𒋗𒉡 𒅋𒇷𒆪 𒌷𒎌 X X 𒌍𒋗𒋾 𒆕𒍑 𒄿𒈾 𒌋𒅗 𒇯 𒄰𒊑\\nX X X...         184   \n","Q003419  𒀀𒈾 𒌍𒋗𒋼 𒀝𒋓𒈠 𒆳 GN 𒀀𒈾 X\\n𒌷 𒆕𒍑 𒂍𒃲 𒈬𒉺𒅁 X X X X X\\n𒈬...         111   \n","Q003420  X X SN SN SN SN SN\\nX 𒆳𒂊 𒊭 GN 𒋗𒋛 𒆳𒂊 𒃻𒆥𒌅 𒄑𒁀𒌅 𒅈𒆠...         141   \n","...                                                    ...         ...   \n","Q009293  X X 𒋗𒈨𒋙 𒆏𒋼 X\\nX X 𒋳𒉌𒂊 𒈬𒅆 𒃻 X X\\nX X X X X X\\nX...          38   \n","Q009294  X X X X X X X\\nX X\\nX X 𒋾𒆷 X X X X\\nX X 𒆠𒆗𒋙 𒌑𒃻...          84   \n","Q009295  X X X X X X X\\nX X 𒆠𒂊𒉡 𒂊𒌓 X X\\n𒂷𒆪 𒇷𒀪𒌋 𒀀𒄭𒄑 𒉌𒈨𒅅 ...          80   \n","Q009297  X X X X X X X X X X X X X\\nX X X X X X X X X X...         204   \n","Q009298  DN 𒅇 X X\\nX 𒄿𒁲 𒈗 X X\\nX X X\\nX X 𒋙 X X X X X X...         183   \n","\n","        partial_length  \n","Q003414             35  \n","Q003417             36  \n","Q003418             98  \n","Q003419             54  \n","Q003420            115  \n","...                ...  \n","Q009293             10  \n","Q009294             22  \n","Q009295             39  \n","Q009297             23  \n","Q009298             85  \n","\n","[308 rows x 34 columns]"],"text/html":["\n","  <div id=\"df-9bf59613-3ceb-44c2-8322-b4ae631f40e2\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>langs</th>\n","      <th>project</th>\n","      <th>cdli_id</th>\n","      <th>collection</th>\n","      <th>credits</th>\n","      <th>date_of_origin</th>\n","      <th>designation</th>\n","      <th>display_name</th>\n","      <th>dynastic_seat</th>\n","      <th>exemplars</th>\n","      <th>...</th>\n","      <th>script_type</th>\n","      <th>subgenre</th>\n","      <th>supergenre</th>\n","      <th>trans</th>\n","      <th>id_text</th>\n","      <th>seal_id</th>\n","      <th>attribution</th>\n","      <th>text</th>\n","      <th>full_length</th>\n","      <th>partial_length</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Q003414</th>\n","      <td>0x08000000</td>\n","      <td>rinap/rinap1</td>\n","      <td>P463047</td>\n","      <td>Archäologisches Institut der Universität Züric...</td>\n","      <td>Created by Hayim Tadmor, Shigeo Yamada, Jamie ...</td>\n","      <td>744-727</td>\n","      <td>Tiglath-pileser III 01</td>\n","      <td>RINAP 1 Tigl. III 01</td>\n","      <td>Assyria</td>\n","      <td>ZhArchSlg 1917 (+) ZhArchSlg 1918 (+) NA 12/76</td>\n","      <td>...</td>\n","      <td>Cuneiform</td>\n","      <td>Tiglath-pileser III</td>\n","      <td>LIT</td>\n","      <td>['en']</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td>𒉭 𒁄𒌀𒆠 X 𒈾𒉘 X X 𒀊 𒁀 X X\\n𒉿𒄘 X 𒃻 𒀀𒈾 𒁁𒂁 X X 𒀭 𒋾 𒀠...</td>\n","      <td>75</td>\n","      <td>35</td>\n","    </tr>\n","    <tr>\n","      <th>Q003417</th>\n","      <td>0x08000000</td>\n","      <td>rinap/rinap1</td>\n","      <td>P463048</td>\n","      <td></td>\n","      <td>Created by Hayim Tadmor, Shigeo Yamada, Jamie ...</td>\n","      <td>744-727</td>\n","      <td>Tiglath-pileser III 04</td>\n","      <td>RINAP 1 Tigl. III 04</td>\n","      <td>Assyria</td>\n","      <td>NA 09/76</td>\n","      <td>...</td>\n","      <td>Cuneiform</td>\n","      <td>Tiglath-pileser III</td>\n","      <td>LIT</td>\n","      <td>['en']</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td>𒄿𒈾 𒊕 𒈗𒋾𒅀 𒄿𒈾 𒈤𒊑𒂊 𒁄𒅀 𒄿𒈾 n X\\n𒊭 𒄿𒈾 𒄑𒄖𒍝 𒈗𒌑𒋾 𒊏𒄫 𒌑𒅆𒁍...</td>\n","      <td>37</td>\n","      <td>36</td>\n","    </tr>\n","    <tr>\n","      <th>Q003418</th>\n","      <td>0x08000000</td>\n","      <td>rinap/rinap1</td>\n","      <td>P463049</td>\n","      <td>British Museum, London, UK</td>\n","      <td>Created by Hayim Tadmor, Shigeo Yamada, Jamie ...</td>\n","      <td>744-727</td>\n","      <td>Tiglath-pileser III 05</td>\n","      <td>RINAP 1 Tigl. III 05</td>\n","      <td>Assyria</td>\n","      <td>BM 118934 (Layard, MS A pp. 113-114)</td>\n","      <td>...</td>\n","      <td>Cuneiform</td>\n","      <td>Tiglath-pileser III</td>\n","      <td>LIT</td>\n","      <td>['en']</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td>X X 𒀀𒈾 𒆳𒋗𒉡 𒅋𒇷𒆪 𒌷𒎌 X X 𒌍𒋗𒋾 𒆕𒍑 𒄿𒈾 𒌋𒅗 𒇯 𒄰𒊑\\nX X X...</td>\n","      <td>184</td>\n","      <td>98</td>\n","    </tr>\n","    <tr>\n","      <th>Q003419</th>\n","      <td>0x08000000</td>\n","      <td>rinap/rinap1</td>\n","      <td>P463049</td>\n","      <td>British Museum, London, UK</td>\n","      <td>Created by Hayim Tadmor, Shigeo Yamada, Jamie ...</td>\n","      <td>744-727</td>\n","      <td>Tiglath-pileser III 06</td>\n","      <td>RINAP 1 Tigl. III 06</td>\n","      <td>Assyria</td>\n","      <td>BM 118934 (Layard, MS A p. 114)</td>\n","      <td>...</td>\n","      <td>Cuneiform</td>\n","      <td>Tiglath-pileser III</td>\n","      <td>LIT</td>\n","      <td>['en']</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td>𒀀𒈾 𒌍𒋗𒋼 𒀝𒋓𒈠 𒆳 GN 𒀀𒈾 X\\n𒌷 𒆕𒍑 𒂍𒃲 𒈬𒉺𒅁 X X X X X\\n𒈬...</td>\n","      <td>111</td>\n","      <td>54</td>\n","    </tr>\n","    <tr>\n","      <th>Q003420</th>\n","      <td>0x08000000</td>\n","      <td>rinap/rinap1</td>\n","      <td>P463050</td>\n","      <td>British Museum, London, UK</td>\n","      <td>Created by Hayim Tadmor, Shigeo Yamada, Jamie ...</td>\n","      <td>744-727</td>\n","      <td>Tiglath-pileser III 07</td>\n","      <td>RINAP 1 Tigl. III 07</td>\n","      <td>Assyria</td>\n","      <td>BM 118933 (Layard, MS A pp. 111-112)</td>\n","      <td>...</td>\n","      <td>Cuneiform</td>\n","      <td>Tiglath-pileser III</td>\n","      <td>LIT</td>\n","      <td>['en']</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td>X X SN SN SN SN SN\\nX 𒆳𒂊 𒊭 GN 𒋗𒋛 𒆳𒂊 𒃻𒆥𒌅 𒄑𒁀𒌅 𒅈𒆠...</td>\n","      <td>141</td>\n","      <td>115</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>Q009293</th>\n","      <td>0x08000000</td>\n","      <td>rinap/rinap5</td>\n","      <td></td>\n","      <td>British Museum, London, UK</td>\n","      <td>Created by Jamie Novotny and Joshua Jeffers, 2...</td>\n","      <td>668-ca. 631</td>\n","      <td>Ashurbanipal 1025</td>\n","      <td>RINAP 5 Asb. 1025</td>\n","      <td>Assyria</td>\n","      <td>K 04498</td>\n","      <td>...</td>\n","      <td>Cuneiform</td>\n","      <td>Ashurbanipal</td>\n","      <td>LIT</td>\n","      <td>['en']</td>\n","      <td></td>\n","      <td></td>\n","      <td>Created by Jamie Novotny and Joshua Jeffers, 2...</td>\n","      <td>X X 𒋗𒈨𒋙 𒆏𒋼 X\\nX X 𒋳𒉌𒂊 𒈬𒅆 𒃻 X X\\nX X X X X X\\nX...</td>\n","      <td>38</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>Q009294</th>\n","      <td>0x08000000</td>\n","      <td>rinap/rinap5</td>\n","      <td></td>\n","      <td>British Museum, London, UK</td>\n","      <td>Created by Jamie Novotny and Joshua Jeffers, 2...</td>\n","      <td>668-ca. 631</td>\n","      <td>Ashurbanipal 1026</td>\n","      <td>RINAP 5 Asb. 1026</td>\n","      <td>Assyria</td>\n","      <td>K 08361</td>\n","      <td>...</td>\n","      <td>Cuneiform</td>\n","      <td>Ashurbanipal</td>\n","      <td>LIT</td>\n","      <td>['en']</td>\n","      <td></td>\n","      <td></td>\n","      <td>Created by Jamie Novotny and Joshua Jeffers, 2...</td>\n","      <td>X X X X X X X\\nX X\\nX X 𒋾𒆷 X X X X\\nX X 𒆠𒆗𒋙 𒌑𒃻...</td>\n","      <td>84</td>\n","      <td>22</td>\n","    </tr>\n","    <tr>\n","      <th>Q009295</th>\n","      <td>0x08000000</td>\n","      <td>rinap/rinap5</td>\n","      <td></td>\n","      <td>British Museum, London, UK</td>\n","      <td>Created by Jamie Novotny and Joshua Jeffers, 2...</td>\n","      <td>668-ca. 631</td>\n","      <td>Ashurbanipal 1027</td>\n","      <td>RINAP 5 Asb. 1027</td>\n","      <td>Assyria</td>\n","      <td>K 06681</td>\n","      <td>...</td>\n","      <td>Cuneiform</td>\n","      <td>Ashurbanipal</td>\n","      <td>LIT</td>\n","      <td>['en']</td>\n","      <td></td>\n","      <td></td>\n","      <td>Created by Jamie Novotny and Joshua Jeffers, 2...</td>\n","      <td>X X X X X X X\\nX X 𒆠𒂊𒉡 𒂊𒌓 X X\\n𒂷𒆪 𒇷𒀪𒌋 𒀀𒄭𒄑 𒉌𒈨𒅅 ...</td>\n","      <td>80</td>\n","      <td>39</td>\n","    </tr>\n","    <tr>\n","      <th>Q009297</th>\n","      <td>0x08000000</td>\n","      <td>rinap/rinap5</td>\n","      <td></td>\n","      <td>British Museum, London, UK</td>\n","      <td>Created by Jamie Novotny and Joshua Jeffers, 2...</td>\n","      <td>668-ca. 631</td>\n","      <td>Ashurbanipal 1029</td>\n","      <td>RINAP 5 Asb. 1029</td>\n","      <td>Assyria</td>\n","      <td>Bu 1891-05-09, 0204</td>\n","      <td>...</td>\n","      <td>Cuneiform</td>\n","      <td>Ashurbanipal</td>\n","      <td>LIT</td>\n","      <td>['en']</td>\n","      <td></td>\n","      <td></td>\n","      <td>Created by Jamie Novotny and Joshua Jeffers, 2...</td>\n","      <td>X X X X X X X X X X X X X\\nX X X X X X X X X X...</td>\n","      <td>204</td>\n","      <td>23</td>\n","    </tr>\n","    <tr>\n","      <th>Q009298</th>\n","      <td>0x08000000</td>\n","      <td>rinap/rinap5</td>\n","      <td></td>\n","      <td></td>\n","      <td>Created by Jamie Novotny and Joshua Jeffers, 2...</td>\n","      <td>668-ca. 631</td>\n","      <td>Ashurbanipal 1030</td>\n","      <td>RINAP 5 Asb. 1030</td>\n","      <td>Assyria</td>\n","      <td>Shikaft-i Gulgul rock relief</td>\n","      <td>...</td>\n","      <td>Cuneiform</td>\n","      <td>Ashurbanipal</td>\n","      <td>LIT</td>\n","      <td>['en']</td>\n","      <td></td>\n","      <td></td>\n","      <td>Created by Jamie Novotny and Joshua Jeffers, 2...</td>\n","      <td>DN 𒅇 X X\\nX 𒄿𒁲 𒈗 X X\\nX X X\\nX X 𒋙 X X X X X X...</td>\n","      <td>183</td>\n","      <td>85</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>308 rows × 34 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9bf59613-3ceb-44c2-8322-b4ae631f40e2')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-9bf59613-3ceb-44c2-8322-b4ae631f40e2 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-9bf59613-3ceb-44c2-8322-b4ae631f40e2');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-cb8a0de6-c362-4109-a60f-04ebef5adc26\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cb8a0de6-c362-4109-a60f-04ebef5adc26')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-cb8a0de6-c362-4109-a60f-04ebef5adc26 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_dc4a1690-67e5-40cb-b736-1a73caab5a0b\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('corpus_metadata')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_dc4a1690-67e5-40cb-b736-1a73caab5a0b button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('corpus_metadata');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"corpus_metadata"}},"metadata":{},"execution_count":33}]},{"cell_type":"markdown","source":["# Exploring the Akkadian RINAP or Egyptian TLA Corpus using the Vector Space Model"],"metadata":{"id":"cRwY7N32zfQR"}},{"cell_type":"code","source":["# vectorize corpus\n","counts, counts_df, stop_words = vectorize(corpus_metadata, max_features=50)"],"metadata":{"id":"mm3YZQGs4x1Y","executionInfo":{"status":"error","timestamp":1737386223244,"user_tz":-120,"elapsed":231,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}},"colab":{"base_uri":"https://localhost:8080/","height":284},"outputId":"785fe316-cf01-43a7-ad3d-d5867f82b6eb"},"execution_count":34,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'TfidfVectorizer' object has no attribute 'stop_words_'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-aff4c3b0c5e7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# vectorize corpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_metadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-24-98d993df18b8>\u001b[0m in \u001b[0;36mvectorize\u001b[0;34m(corpus, analyzer, ngram_range, max_df, min_df, max_features, stop_words)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mstop_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_words_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# saving the vocab used for vectorization, and switching the dictionary so that the feature index is the key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'TfidfVectorizer' object has no attribute 'stop_words_'"]}]},{"cell_type":"code","source":["counts_df.head(3)"],"metadata":{"id":"PZtqUY6uNj7s","colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"status":"error","timestamp":1737386258681,"user_tz":-120,"elapsed":264,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}},"outputId":"cef15bc2-86e2-4308-f645-1749a32dcf0d"},"execution_count":35,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'counts_df' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-1b16ba636d60>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcounts_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'counts_df' is not defined"]}]},{"cell_type":"code","source":["# calculate distance between vectorized texts\n","matrix = distance_calculator(counts, \"cosine\", corpus_metadata.index)\n","matrix"],"metadata":{"id":"MFoQOq7w5QnY","executionInfo":{"status":"aborted","timestamp":1737385521418,"user_tz":-120,"elapsed":13266,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# visualize matrix\n","fig = px.imshow(matrix)\n","\n","# adjust size of the matrix\n","fig.update_layout(\n","    autosize=False,\n","    width=1500,\n","    height=1500,\n",")\n","fig.show()"],"metadata":{"id":"aP65l1sGDdIJ","executionInfo":{"status":"aborted","timestamp":1737385521418,"user_tz":-120,"elapsed":13265,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# reduce matrix dimensions\n","reduced_tsne = reduce_dimensions_tsne(matrix, perplexity=matrix.shape[0]**0.5, n_iter=5000, metric=\"euclidean\", metadata=corpus_metadata)"],"metadata":{"id":"zodSXjV_Dsco","executionInfo":{"status":"aborted","timestamp":1737385521418,"user_tz":-120,"elapsed":13264,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# visualize reduced dimensions\n","\n","# adjust size column for visualization\n","size_min = 3\n","size_max = 70\n","size = (reduced_tsne[\"partial_length\"] / reduced_tsne[\"partial_length\"].max() * (size_max - size_min) + size_min).tolist()\n","\n","# create figure\n","# for Akkadian use symbol = \"script\", color=\"project\",\n","# for Egyptian\n","fig = px.scatter(reduced_tsne, x=\"component 1\", y=\"component 2\", size=size, symbol = \"corpus_manual\", color=\"language_manual\", hover_data=[\"partial_length\", \"full_length\", reduced_tsne.index])\n","fig.update_traces(marker=dict(line=dict(width=1, color='black')))\n","fig.show()"],"metadata":{"id":"R2sfDFXxRFZX","collapsed":true,"executionInfo":{"status":"aborted","timestamp":1737385521418,"user_tz":-120,"elapsed":13262,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Find Shared Tokens"],"metadata":{"id":"vzE4jn2aywPY"}},{"cell_type":"markdown","source":["**creates a mini df that includes only the chosen text and the shared tokens in those texts**\n","  (i.e., all tokens that are none zero in all texts).\n","* param df: the counts_df where the index is the text ids and the columns are the tokens.\n","* param text_ids: a list containing text ids.\n","* return: a dataframe where the index are the shared tokens and the columns are the texts.\n","           the values are the tf-idf scores."],"metadata":{"id":"stQkSTdPIFeF"}},{"cell_type":"code","source":["def find_shared_tokens(df, text_ids):\n","\n","  mini_df = df[df.index.isin(text_ids)].copy()\n","  mini_df = mini_df.loc[:, (mini_df != 0).all(axis=0)].copy()\n","  return mini_df.transpose()"],"metadata":{"id":"O1luauCfQOJ2","executionInfo":{"status":"aborted","timestamp":1737385521419,"user_tz":-120,"elapsed":13262,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Akkadian\n","shared_tokens = find_shared_tokens(counts_df, [\"Q003450\", \"Q003711\", \"Q003790\"])\n","# Egyptian\n","#shared_tokens = find_shared_tokens(counts_df, [\"pEdwinSmith_Wundenbuch_1-27\", \"pEdwinSmith_Wundenbuch_28-48\", \"pEdwinSmith_Hautverschoenerung\", \"pEbers_432-436\"])#, \"3RU7Z4VQ45CYFIQ4PUGQ3HDJFU\"])\n","\n","shared_tokens"],"metadata":{"id":"TrUxwzx80mWh","executionInfo":{"status":"aborted","timestamp":1737385521419,"user_tz":-120,"elapsed":13261,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["px.scatter(shared_tokens)"],"metadata":{"id":"-uJwKsBC2usV","executionInfo":{"status":"aborted","timestamp":1737385521419,"user_tz":-120,"elapsed":13260,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*This notebook was created by [Avital Romach](https://github.com/ARomach), with additional code and text by [Eliese-Sophia Lincke](https://www.geschkult.fu-berlin.de/e/aegyptologie/personen/Professorinnen-und-Professoren/Lincke/index.html), [Shai Gordin](https://digitalpasts.github.io/) and [Daniel A. Werning](https://www.bbaw.de/die-akademie/mitarbeiterinnen-mitarbeiter/werning-daniel) in Spring 2024 for the course [Ancient Language Processing](https://digitalpasts.github.io/ALP-course/). Code can be reused under a [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/)*"],"metadata":{"id":"rHqa0j0mMm7x"}},{"cell_type":"code","source":[],"metadata":{"id":"Q-IOsnZuQyfB","executionInfo":{"status":"aborted","timestamp":1737385521739,"user_tz":-120,"elapsed":1,"user":{"displayName":"shai gordin","userId":"12645290687300756012"}}},"execution_count":null,"outputs":[]}]}